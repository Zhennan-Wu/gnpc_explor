{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2eafefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# folder = \"../data/GNPC_Harmonized_Dataset_V1/\"\n",
    "# file_count = 0\n",
    "# for file in os.listdir(folder):\n",
    "#     if file.endswith(\".csv\"):\n",
    "#         file_count += 1\n",
    "#         path = os.path.join(folder, file)\n",
    "\n",
    "#         print(\"=\" * 100)\n",
    "#         print(f\"Reading: {file}\")\n",
    "#         print(\"=\" * 100)\n",
    "\n",
    "#         try:\n",
    "#             df = pd.read_csv(path, encoding=\"utf-8\", engine=\"python\")\n",
    "#         except:\n",
    "#             df = pd.read_csv(path, encoding=\"latin1\", engine=\"python\")\n",
    "\n",
    "#         print(\"\\nHEAD:\")\n",
    "#         print(df.head())\n",
    "\n",
    "#         print(\"\\nINFO:\")\n",
    "#         df.info()\n",
    "\n",
    "#         print(\"\\n\\n\")\n",
    "\n",
    "# print(f\"Total CSV files processed: {file_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "493a7553",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filepath = \"../data/GNPC_Harmonized_Dataset_V1/Sample to person mapping table for longitudinal samples data dictionary.csv\"\n",
    "# df1 = pd.read_csv(filepath, encoding=\"utf-8\", engine=\"python\")\n",
    "# df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fcb70991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filepath = \"../data/GNPC_Harmonized_Dataset_V1/Disease-specific genotyping data dictionary.csv\"\n",
    "# df2 = pd.read_csv(filepath, encoding=\"utf-8\", engine=\"python\")\n",
    "# df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "098ae0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filepath = \"../data/GNPC_Harmonized_Dataset_V1/Clinical data dictionary.csv\"\n",
    "# df3 = pd.read_csv(filepath, encoding=\"utf-8\", engine=\"python\")\n",
    "# df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7cf4ddfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# pd.testing.assert_frame_equal(df3, df1)\n",
    "# print(\"DataFrames are exactly the same.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbac0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "indices = [\"01\", \"02\", \"03\", \"04\", \"05\", \"06\", \"07\", \"08\", \"09\", \"10\", \"11\", \"12\"]\n",
    "for i in indices:\n",
    "    file = f\"../data/GNPC_Harmonized_Dataset_V1/Somalogic{i}V1_anonymized.csv\"\n",
    "    try:\n",
    "        df = pd.read_csv(file, encoding=\"utf-8\", engine=\"python\")\n",
    "    except:\n",
    "        df = pd.read_csv(file, encoding=\"latin1\", engine=\"python\")\n",
    "\n",
    "#     print(\"\\nHEAD:\")\n",
    "#     print(df.head())\n",
    "\n",
    "#     print(\"\\nINFO:\")\n",
    "#     df.info()\n",
    "#     dfs.append(df)\n",
    "\n",
    "#     print(\"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f3cf190a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identical DataFrame groups (by indices): []\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def find_identical_dfs(df_list):\n",
    "    \"\"\"\n",
    "    Given a list of DataFrames, return groups of indices where the DataFrames are identical.\n",
    "    \"\"\"\n",
    "    # Compute a stable hash for each DataFrame (content + index + columns)\n",
    "    hashes = []\n",
    "    for df in df_list:\n",
    "        h = pd.util.hash_pandas_object(df, index=True).sum()  # reduce to single value\n",
    "        hashes.append(h)\n",
    "\n",
    "    # Group indices by hash value\n",
    "    from collections import defaultdict\n",
    "    groups = defaultdict(list)\n",
    "\n",
    "    for idx, h in enumerate(hashes):\n",
    "        groups[h].append(idx)\n",
    "\n",
    "    # Keep only groups with duplicates\n",
    "    identical_groups = [g for g in groups.values() if len(g) > 1]\n",
    "\n",
    "    return identical_groups\n",
    "identical_groups = find_identical_dfs(dfs)\n",
    "print(\"Identical DataFrame groups (by indices):\", identical_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "65e9943c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of float columns: 7745\n"
     ]
    }
   ],
   "source": [
    "total_float_cols = sum(\n",
    "    df.select_dtypes(include=\"float\").shape[1]\n",
    "    for df in dfs\n",
    ")\n",
    "\n",
    "print(\"Total number of float columns:\", total_float_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3917ecb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_df = pd.read_csv(\"../data/GNPC_Harmonized_Dataset_V1/SomalogicAnalyteInfoV1_anonymized.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "68bc4682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Float columns NOT in ref list: {'seq_14222_68', 'seq_10367_26', 'seq_6096_23', 'seq_2626_3', 'seq_9731_29', 'seq_12926_118', 'seq_14089_41', 'seq_10450_3', 'seq_8487_62', 'seq_10696_217', 'seq_8362_102', 'seq_8816_44', 'seq_9777_138', 'seq_8484_8', 'seq_14704_10', 'seq_9466_43', 'seq_7696_104', 'seq_3737_6', 'seq_11244_63', 'seq_4475_60', 'seq_5766_6', 'seq_5647_51', 'seq_14169_66', 'seq_5059_8', 'seq_9304_27', 'seq_12908_15', 'seq_5071_3', 'seq_3743_1', 'seq_8370_102', 'seq_11835_8', 'seq_2455_17', 'seq_14582_57', 'seq_6240_55', 'seq_3031_66', 'seq_6601_1', 'seq_10009_2', 'seq_9560_56', 'seq_13592_22', 'seq_5095_7', 'seq_5118_74', 'seq_6634_4', 'seq_5247_17', 'seq_6973_2', 'seq_10492_51', 'seq_10735_12', 'seq_8683_119', 'seq_7220_20', 'seq_5073_30', 'seq_11108_16', 'seq_9921_14', 'seq_10387_1', 'seq_8765_23', 'seq_13400_13', 'seq_9382_110', 'seq_11124_9', 'seq_11505_1', 'seq_9307_3', 'seq_11170_9', 'seq_10795_32', 'seq_4494_63', 'seq_8379_35', 'seq_8644_101', 'seq_8827_1', 'seq_8829_4', 'seq_14272_43', 'seq_6956_37', 'seq_10422_44', 'seq_10872_103', 'seq_3700_15', 'seq_13718_1', 'seq_3590_8', 'seq_8256_57', 'seq_11267_11', 'seq_6643_62', 'seq_3893_55', 'seq_6650_20', 'seq_4593_11', 'seq_2795_23', 'seq_10635_33', 'seq_8339_72', 'seq_4695_49', 'seq_11259_71', 'seq_4550_3', 'seq_11276_1', 'seq_8387_33', 'seq_10901_334', 'seq_2914_65', 'seq_6297_49', 'seq_2292_17', 'seq_7093_20', 'seq_9356_20', 'seq_13428_52', 'seq_6484_11', 'seq_10689_5', 'seq_9189_76', 'seq_7195_12', 'seq_14643_27', 'seq_8798_29', 'seq_13716_259', 'seq_10878_1', 'seq_14495_161'}\n",
      "Count: 101\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ref_df[\"column_names\"] is assumed to be a Series or list of names to exclude\n",
    "excluded = set(ref_df[\"column_name\"].astype(str))\n",
    "\n",
    "float_cols = set()\n",
    "\n",
    "for df in dfs:\n",
    "    for col, dtype in df.dtypes.items():\n",
    "        if pd.api.types.is_float_dtype(dtype) and col not in excluded:\n",
    "            float_cols.add(col)\n",
    "\n",
    "print(\"Float columns NOT in ref list:\", float_cols)\n",
    "print(\"Count:\", len(float_cols))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bb75642a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17498/3568567435.py:1: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(\"../data/GNPC_Harmonized_Dataset_V1/SomalogicMetaV1_anonymized.csv\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>contributor_code</th>\n",
       "      <th>visit</th>\n",
       "      <th>plate_id</th>\n",
       "      <th>units</th>\n",
       "      <th>anml_fraction_used_0_005</th>\n",
       "      <th>anml_fraction_used_0_5</th>\n",
       "      <th>anml_fraction_used_20</th>\n",
       "      <th>anml_fraction_used_20_s1</th>\n",
       "      <th>anml_fraction_used_20_s2</th>\n",
       "      <th>...</th>\n",
       "      <th>hyb_control_norm_scale</th>\n",
       "      <th>norm_scale_0_005</th>\n",
       "      <th>norm_scale_0_5</th>\n",
       "      <th>norm_scale_20</th>\n",
       "      <th>norm_scale_20_s1</th>\n",
       "      <th>norm_scale_20_s2</th>\n",
       "      <th>norm_scale_20_s3</th>\n",
       "      <th>row_check</th>\n",
       "      <th>sample_matrix</th>\n",
       "      <th>sample_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19805</th>\n",
       "      <td>b85fc5cb-6b57-49ec-b411-eb133fcc5db2</td>\n",
       "      <td>U</td>\n",
       "      <td>6</td>\n",
       "      <td>79</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.957</td>\n",
       "      <td>0.942</td>\n",
       "      <td>0.952</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.944135</td>\n",
       "      <td>1.32690</td>\n",
       "      <td>1.117937</td>\n",
       "      <td>1.017498</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>PASS</td>\n",
       "      <td>Serum</td>\n",
       "      <td>Sample</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21523</th>\n",
       "      <td>e89a1858-26fb-40d3-8eb5-db14e4ac0212</td>\n",
       "      <td>U</td>\n",
       "      <td>6</td>\n",
       "      <td>102</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.979</td>\n",
       "      <td>0.926</td>\n",
       "      <td>0.950</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.889716</td>\n",
       "      <td>1.22066</td>\n",
       "      <td>1.085707</td>\n",
       "      <td>1.075381</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>PASS</td>\n",
       "      <td>Serum</td>\n",
       "      <td>Sample</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  sample_id contributor_code  visit  plate_id  \\\n",
       "19805  b85fc5cb-6b57-49ec-b411-eb133fcc5db2                U      6        79   \n",
       "21523  e89a1858-26fb-40d3-8eb5-db14e4ac0212                U      6       102   \n",
       "\n",
       "      units  anml_fraction_used_0_005  anml_fraction_used_0_5  \\\n",
       "19805    -1                     0.957                   0.942   \n",
       "21523    -1                     0.979                   0.926   \n",
       "\n",
       "       anml_fraction_used_20  anml_fraction_used_20_s1  \\\n",
       "19805                  0.952                      -1.0   \n",
       "21523                  0.950                      -1.0   \n",
       "\n",
       "       anml_fraction_used_20_s2  ...  hyb_control_norm_scale  \\\n",
       "19805                      -1.0  ...                0.944135   \n",
       "21523                      -1.0  ...                0.889716   \n",
       "\n",
       "       norm_scale_0_005  norm_scale_0_5  norm_scale_20  norm_scale_20_s1  \\\n",
       "19805           1.32690        1.117937       1.017498              -1.0   \n",
       "21523           1.22066        1.085707       1.075381              -1.0   \n",
       "\n",
       "       norm_scale_20_s2  norm_scale_20_s3  row_check sample_matrix sample_type  \n",
       "19805              -1.0              -1.0       PASS         Serum      Sample  \n",
       "21523              -1.0              -1.0       PASS         Serum      Sample  \n",
       "\n",
       "[2 rows x 21 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../data/GNPC_Harmonized_Dataset_V1/SomalogicMetaV1_anonymized.csv\")\n",
    "data[data[\"visit\"] > 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5a46938",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_74186/1830002650.py:1: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(\"../data/GNPC_Harmonized_Dataset_V1/SomalogicMetaV1_anonymized.csv\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../data/GNPC_Harmonized_Dataset_V1/SomalogicMetaV1_anonymized.csv\")\n",
    "data[\"contributor_code\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9114c17f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16511"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdata = pd.read_csv(\"../data/GNPC_Harmonized_Dataset_V1/PersonMappingV1_anonymized.csv\")\n",
    "unique_count = pdata[pdata['person_id'].duplicated(keep=False) == False].shape[0]\n",
    "unique_count"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnpc",
   "language": "python",
   "name": "gnpc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
